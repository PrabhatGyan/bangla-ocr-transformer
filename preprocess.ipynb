{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Splitting the Datasets\n",
    "Before training the model, you must preprocess the dataset(s) which will create directories containing preprocessed and augmented images. These images will be used to train the model and can be used during inference as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "source_path = 'raw_data'\n",
    "dest_path = 'data'\n",
    "\n",
    "if os.path.exists(os.path.join(dest_path, 'Train')):\n",
    "    shutil.rmtree(os.path.join(dest_path, 'Train'))\n",
    "    shutil.rmtree(os.path.join(dest_path, 'Validation'))\n",
    "\n",
    "os.mkdir(os.path.join(dest_path, 'Binarized'))\n",
    "os.mkdir(os.path.join(dest_path, 'Annotations'))\n",
    "os.mkdir(os.path.join(dest_path, 'Train'))\n",
    "os.mkdir(os.path.join(dest_path, 'Validation'))\n",
    "os.mkdir(os.path.join(dest_path, 'Train', 'Images'))\n",
    "os.mkdir(os.path.join(dest_path, 'Train', 'Annotations'))\n",
    "os.mkdir(os.path.join(dest_path, 'Validation', 'Images'))\n",
    "os.mkdir(os.path.join(dest_path, 'Validation', 'Annotations'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize each dataset and dump Images and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 'Bongabdo' preprocessing : 3 images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def binarize(image): # image <- cv2 image\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 10)\n",
    "    return binary\n",
    "\n",
    "all_datasets = os.listdir(source_path)\n",
    "for dataset in all_datasets:\n",
    "    dataset_path = os.path.join(source_path, dataset)\n",
    "    all_images = os.listdir(os.path.join(dataset_path, 'Images'))\n",
    "    all_annotations = os.listdir(os.path.join(dataset_path, 'Annotations'))\n",
    "    if len(all_images) > 0:\n",
    "        for img in all_images:\n",
    "            image = cv2.imread(os.path.join(dataset_path, 'Images', img), 0)\n",
    "            binarized = binarize(image)\n",
    "            cv2.imwrite(os.path.join(dest_path, 'Binarized', img), binarized)\n",
    "        \n",
    "        for gt in all_annotations :\n",
    "            shutil.copy(os.path.join(dataset_path, 'Annotations', gt), os.path.join(dest_path, 'Annotations', gt))\n",
    "        print(f\"Completed '{dataset}' preprocessing : {len(all_images)} images\")\n",
    "    else:\n",
    "        print(f\"Dataset {dataset} images not found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation of Preprocessed data and Generating duplicate GTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Augmentation, Number of Images : 3\n",
      "After Augmentation, Number of Images : 21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "img_path = os.path.join(dest_path, 'Binarized')\n",
    "gt_path = os.path.join(dest_path, 'Annotations')\n",
    "all_images = os.listdir(img_path)\n",
    "print(f\"Before Augmentation, Number of Images : {len(all_images)}\")\n",
    "\n",
    "for img in all_images:\n",
    "    original = Image.open(os.path.join(img_path, img))\n",
    "    image = img.rsplit('.', maxsplit = 1)[0]\n",
    "    c=1\n",
    "\n",
    "    # Rotate 2.5 anticlockwise\n",
    "    new = original.rotate(2.5, expand=True, fillcolor=255)\n",
    "    new.save(os.path.join(img_path, f\"{image}_{c}.jpg\"))\n",
    "    shutil.copy(os.path.join(gt_path, f\"{image}.txt\"), os.path.join(gt_path, f\"{image}_{c}.txt\"))\n",
    "    c += 1\n",
    "\n",
    "    # Rotate 5 anticlockwise\n",
    "    new = original.rotate(5, expand=True, fillcolor=255)\n",
    "    new.save(os.path.join(img_path, f\"{image}_{c}.jpg\"))\n",
    "    shutil.copy(os.path.join(gt_path, f\"{image}.txt\"), os.path.join(gt_path, f\"{image}_{c}.txt\"))\n",
    "    c += 1\n",
    "\n",
    "    # Rotate 2.5 clockwise\n",
    "    new = original.rotate(-2.5, expand=True, fillcolor=255)\n",
    "    new.save(os.path.join(img_path, f\"{image}_{c}.jpg\"))\n",
    "    shutil.copy(os.path.join(gt_path, f\"{image}.txt\"), os.path.join(gt_path, f\"{image}_{c}.txt\"))\n",
    "    c += 1\n",
    "\n",
    "    # Rotate 5 clockwise\n",
    "    new = original.rotate(-5, expand=True, fillcolor=255)\n",
    "    new.save(os.path.join(img_path, f\"{image}_{c}.jpg\"))\n",
    "    shutil.copy(os.path.join(gt_path, f\"{image}.txt\"), os.path.join(gt_path, f\"{image}_{c}.txt\"))\n",
    "    c += 1\n",
    "\n",
    "    enhancer = ImageEnhance.Brightness(original)\n",
    "    \n",
    "    # Increase Brightness\n",
    "    new = enhancer.enhance(5)\n",
    "    new.save(os.path.join(img_path, f\"{image}_{c}.jpg\"))\n",
    "    shutil.copy(os.path.join(gt_path, f\"{image}.txt\"), os.path.join(gt_path, f\"{image}_{c}.txt\"))\n",
    "    c += 1\n",
    "    \n",
    "    # Decrease Brightness\n",
    "    new = enhancer.enhance(0.85)\n",
    "    new.save(os.path.join(img_path, f\"{image}_{c}.jpg\"))\n",
    "    shutil.copy(os.path.join(gt_path, f\"{image}.txt\"), os.path.join(gt_path, f\"{image}_{c}.txt\"))\n",
    "\n",
    "print(f\"After Augmentation, Number of Images : {len(os.listdir(os.path.join(img_path)))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code checks if the Annotations of the corresponding Images in Train split have been copied accordingly within Train split after Augmentation. This should output `True` in case the Images and corresponding Annotations have been properly copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set check : True\n",
      "Train images : 21\tTrain Annotations : 21\tTrue\n"
     ]
    }
   ],
   "source": [
    "all_imgs = [i.rsplit('.', maxsplit=1)[0] for i in os.listdir(os.path.join(dest_path, 'Binarized'))]\n",
    "all_gt = [i.rsplit('.', maxsplit=1)[0] for i in os.listdir(os.path.join(dest_path, 'Annotations'))]\n",
    "\n",
    "print(f\"Train set check : {all_imgs == all_gt}\")\n",
    "print(f\"Train images : {len(all_imgs)}\\tTrain Annotations : {len(all_gt)}\\t{len(all_imgs) == len(all_gt)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeAugmentedImages(image : str):\n",
    "    img = cv2.imread(image, 0)\n",
    "    h, w = img.shape[0], img.shape[1] # (h, w)\n",
    "    new_height = int(np.ceil((w * 16)/9))\n",
    "    if h > new_height :\n",
    "        new_width = int(np.ceil((h * 9)/16))\n",
    "        new_img = np.full((h, new_width), 255, dtype=np.uint8) # In case of np.full -> (h, w)\n",
    "        new_img[:, :w] = img # (h, w)\n",
    "    else:\n",
    "        new_img = np.full((new_height, w), 255, dtype=np.uint8)\n",
    "        new_img[:h, :] = img # (h, w)\n",
    "    return cv2.resize(new_img, (360, 640))\n",
    "\n",
    "all_imgs = os.listdir(os.path.join(dest_path, 'Binarized'))\n",
    "for img in all_imgs:\n",
    "    cv2.imwrite(os.path.join(dest_path, 'Binarized', img), resizeAugmentedImages(os.path.join(dest_path, 'Binarized', img)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.85\n",
    "\n",
    "import numpy as np\n",
    "all_images = np.array(os.listdir(os.path.join(dest_path, 'Binarized')))\n",
    "total = len(all_images)\n",
    "train_size = int(total * train_ratio)\n",
    "val_size = total - train_size\n",
    "random_permutation = np.random.permutation(total)\n",
    "\n",
    "img_train = all_images[random_permutation[:train_size]]\n",
    "img_val = all_images[random_permutation[-val_size:]]\n",
    "print((len(img_train)+len(img_val)) == total)\n",
    "\n",
    "for img in img_train :\n",
    "    shutil.move(os.path.join(dest_path, 'Binarized', img), os.path.join(dest_path, 'Train', 'Images', img))\n",
    "    gt = img.rsplit('.', maxsplit = 1)[0] + '.txt'\n",
    "    shutil.move(os.path.join(dest_path, 'Annotations', gt), os.path.join(dest_path, 'Train', 'Annotations', gt))\n",
    "for img in img_val :\n",
    "    shutil.move(os.path.join(dest_path, 'Binarized', img), os.path.join(dest_path, 'Validation', 'Images', img))\n",
    "    gt = img.rsplit('.', maxsplit = 1)[0] + '.txt'\n",
    "    shutil.move(os.path.join(dest_path, 'Annotations', gt), os.path.join(dest_path, 'Validation', 'Annotations', gt))\n",
    "\n",
    "if len(os.listdir(os.path.join(dest_path, 'Binarized'))) > 0 :\n",
    "    print(os.listdir(os.path.join(dest_path, 'Binarized')))\n",
    "else:\n",
    "    shutil.rmtree(os.path.join(dest_path, 'Binarized'))\n",
    "if len(os.listdir(os.path.join(dest_path, 'Annotations'))) > 0 :\n",
    "    print(os.listdir(os.path.join(dest_path, 'Annotations')))\n",
    "else:\n",
    "    shutil.rmtree(os.path.join(dest_path, 'Annotations'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code checks if the Annotations of the corresponding Images in Train/Validation splits have been copied accordingly within Train/Validation splits. This should output `True` in case the Images and corresponding Annotations have been properly copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set check : True\n",
      "Validation set check : True\n"
     ]
    }
   ],
   "source": [
    "all_imgs = [i.rsplit('.', maxsplit=1)[0] for i in os.listdir(os.path.join(dest_path, 'Train', 'Images'))]\n",
    "all_gt = [i.rsplit('.', maxsplit=1)[0] for i in os.listdir(os.path.join(dest_path, 'Train', 'Annotations'))]\n",
    "\n",
    "print(f\"Train set check : {all_imgs == all_gt}\")\n",
    "\n",
    "all_imgs = [i.rsplit('.', maxsplit=1)[0] for i in os.listdir(os.path.join(dest_path, 'Validation', 'Images'))]\n",
    "all_gt = [i.rsplit('.', maxsplit=1)[0] for i in os.listdir(os.path.join(dest_path, 'Validation', 'Annotations'))]\n",
    "\n",
    "print(f\"Validation set check : {all_imgs == all_gt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
